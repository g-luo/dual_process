pipe_kwargs:
  min_vram_gb: 44.3
  pipe_id: black-forest-labs/FLUX.1-dev
  pipe_cls: FluxPipeline
  torch_dtype: torch.bfloat16
  scheduler_config:
    train_scheduler_cls: FlowMatchEulerDiscreteScheduler
generator_kwargs:
  height: 512
  width: 512
  num_inference_steps: 28
  guidance_scale: 0
lora_kwargs:
  target_modules:
    - attn.to_k
    - attn.to_q
    - attn.to_v
    - attn.to_out.0
    - attn.add_k_proj
    - attn.add_q_proj
    - attn.add_v_proj
    - attn.to_add_out
    - ff.net.0.proj
    - ff.net.2
    - ff_context.net.0.proj
    - ff_context.net.2