vlm_kwargs:
  min_vram_gb: 17.3
  vlm_id: HuggingFaceM4/idefics2-8b
  vlm_cls: AutoModelForVision2Seq
  load_in_4bit: False
  torch_dtype: torch.bfloat16
vlm_template:
  image_token: "<image>"
  prefix: "User:{image_token}{question}<end_of_utterance>\nAssistant: "